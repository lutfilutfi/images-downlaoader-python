

from selenium import webdriver
from bs4 import BeautifulSoup
import requests
import urllib.request
import time
import sys
import os


# user inputs
download = input("What do you want to download?")
n_images = int(input('How many scrolls worth of images do you want?: '))
maxi = int(input('Upper limit of images to be downloaded?: '))


#if you want to change the folder name in which the image should be downloaded
SAVE_FOLDER = 'images for '
SAVE_FOLDER+=download
#creates a folder in the directory script was called you can change this also
if not os.path.exists(SAVE_FOLDER):
    os.mkdir(SAVE_FOLDER)
fullpath=SAVE_FOLDER+'/'
#+ is added because the url cant have spaces
site = 'https://www.google.com/search?tbm=isch&q='+download.replace(' ','+')


#initiating selenium
#you need this driver gecko driver download it if you dont have
#you also need visual c++
driver = webdriver.Firefox(executable_path ='C:\Drivers\geckodriver.exe')

#passing site url
driver.get(site)


i = 0

while i<n_images:  
	#scrolls the page page
    driver.execute_script("window.scrollBy(0,document.body.scrollHeight)")
    
    try:
		#clicking show more results
        driver.find_element_by_xpath("/html/body/div[2]/c-wiz/div[3]/div[1]/div/div/div/div/div[5]/input").click()
    except Exception as e:
        pass
    time.sleep(5)
    i+=1

#parses the large html generated by scrolls
soup = BeautifulSoup(driver.page_source, 'html.parser')


#closing web browser
driver.close()

#img tags will keep on changing hence i have no idea if this will work in the future,
#but  it works as of july 2020
#if it stops working check the class which have "src: some url of the image" and change the values respectively
#scraping image urls with the help of image tag and class used for images
img_tags = soup.find_all("img", class_="rg_i")


count = 0
for i in img_tags:    #parsing through all tags
    if count>maxi:
        break
    filename='{}.jpg'.format(count)
    filepath='{}{}'.format(fullpath,filename)
    #print(i['src'])   #the link of the img to be dowloaded
    try:
		#passing image urls one by one and downloading
        urllib.request.urlretrieve(i['src'], filepath)
        count+=1
        
    except Exception as e:
        pass

